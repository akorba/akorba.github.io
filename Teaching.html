<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <!--<meta name="viewport" content="width=device-width, shrink-to-fit=no, initial-scale=1">-->
    <meta name="viewport" content="user-scalable = yes">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Anna Korba</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/simple-sidebar.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>

    <div id="wrapper", class="toggled">

        <!-- Sidebar -->
        <div id="sidebar-wrapper">
            <ul class="sidebar-nav">
                <li class="sidebar-brand">
                    <a href="#">
                        <a href="index.html">Home</a>
                    </a>
                </li>
                <li>
                    <a href="#"> <a href="Publications.html">Papers</a> </a>
                </li>
                <li>
                    <a href="#"> <a href="Talks.html">Talks</a> </a>
                </li>
                <li>
                    <a href="#"><a href="Teaching.html">Teaching</a></a>
                </li>
                                <li>
                    <a href="#"><a href="MasterDS.html">ENSAE/M.DS</a></a>
                </li>
                <li>
                    <a href="#"><a href="Contact.html">Contact</a></a>
                </li>
            </ul>
        </div>
        <!-- /#sidebar-wrapper -->

        <!-- Page Content -->
        <div id="page-content-wrapper">
            <div class="container-fluid">
                <div class="row">
                    <div class="col-lg-12">
                        <h1 style="margin-bottom: 50px;">Teaching - Sampling: From MCMC to Generative Modeling</h1>

                            <p style="font-size: 18px;">Please fill the following questionnaire:</a>
                        </p>
                         <ul style="padding-left:0;margin-left: 1.2em;font-size: 15px;">
                            <li> <a href="https://docs.google.com/forms/d/e/1FAIpQLSd0dRPNTX2q_8O3L2GDnlbUch6IFX3F5ImuB5tJxev-ucVWDA/viewform?usp=sf_link">Questionnaire</a> <br> 
                            </li>
                         </ul>

                        <p style="font-size: 18px;">Course</a>
                        </p>
                        Dates: 26th, 27th morning; 2nd, 16th, 23rd, 30th (afternoon). At least 2 practical sessions (2nd - Langevin Monte Carlo - and 30th). Bring your computers.
                        <br><br>
                        Slides are in construction and are susceptible to change by the time I teach the course, especially Part III is in construction. Part I~30 slides, Part II~80 slides, Part III~30 slides. Part II is long because we will spend time on some important notions such as gradient flows, score, or continuity equations which are crucial for NF and DM for instance.<br><br>
                         <ul style="padding-left:0;margin-left: 1.2em;font-size: 14px;">
                            
                            <li> <a href="resources/PartI.pdf">Part I</a> Motivation, Divergences between probability distributions, Reminders on basics from MCMC<br>  
                         </li>
                            <li> <a href="resources/PartII.pdf">Part II </a> (Sampling as Optimization of the KL): gradient flows in finite and infinite dimensions, continuity equation, Langevin Monte Carlo<br>  + stochastic Langevin dynamics based on <a href="https://www.di.ens.fr/appstat/spring-2022/lecture_notes/SGLD.pdf"> these notes</a>.
                         </li>
                         <li> Part III (Generative Modeling): Normalizing Flows (NF), Diffusion Models (DM) - if time allows briefly GANs and VAEs.<br>  
                         </li>
                     </ul>

                        <p style="font-size: 14px;">Additional Resources:</a>
                        </p>

                         <ul style="padding-left:0;margin-left: 1.2em;font-size: 14px;">
                            
                            <li> <a href="https://nchopin.github.io/teaching.html">Simulation and Monte Carlo methods</a> by Nicolas Chopin (ENSAE 2A)<br>  
                         </li>
                         <li> <a href"https://www.di.ens.fr/appstat/spring-2022/lecture_notes/SGLD.pdf">Sampling with Langevin and Stochastic Langevin </a> by Umut Simsekli</li>
                            <li> <a href="https://wiki.randaldouc.xyz/lib/exe/fetch.php?media=world:polymcmc.pdf">A crash course in Monte Carlo methods by Markov chains</a> by Randal Douc and Sholom Schechtman<br>  
                         </li>
                         <li> <a href="https://www.math.cuhk.edu.hk/course_builder/2021/math2020b/Chapter%202%20Change%20of%20Variables.pdf">Change of Variables formula</a> Change of Variables formula<br>  
                         </li>
                     </ul>
                     <p style="font-size: 18px;">(Practical) Resources.</a>
                        </p> We won't have time to go through everything of course, but here are several practical Python notebooks that we may go through together or by yourself; or can even serve as a basis for a project if implemented in combination with novel ideas or datasets.
                         <ul style="padding-left:0;margin-left: 1.2em;font-size: 14px;">
                           <li> Langevin Monte carlo/Metropolis Hasting/Hamiltonian Monte Carlo
                            <ul style="padding-left:0;margin-left: 1.2em;font-size: 14px;">

                            <li>Stochastic Langevin with linear model on simulated data <a href="code/Umut_TP.ipynb" download>link</a> (solution after the practical session)</li>
                            <li>Bayesian Logistic Regression on simulated data, <a href="code/Langevin_Monte_Carlo_Logistic_Regression_Simulated_Data.ipynb" download>link</a> </li>
                            <li>Metropolis Hasting, <a href="code/Metropolis_Hastings.ipynb" download>link</a> </li>
                            <li>MALA vs HMC, <a href="code/mh_mala_hmc_correction.ipynb" download>link</a> </li>
                            <!--<li>Bayesian Logistic Regression on real data, <a href="https://bayesball.github.io/BOOK/bayesian-multiple-regression-and-logistic-models.html"> in R</a> or <a href="">Python</a>-->
                        </ul>
                            <li> Normalizing Flows
                            <ul style="padding-left:0;margin-left: 1.2em;font-size: 14px;">
                            <li>Normalizing Flow in 2D on Mixture of Gaussians, <a href="https://github.com/marylou-gabrie/tutorial-sampling-enhanced-w-generative-models/blob/main/sampling_gen_model_tutorial_solutions.ipynb">link</a> - check ReadMe to run it on Google Colab.</li>
                            <li>To go further on Normalizing Flows (on images), <a href="https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial11/NF_image_modeling.html">link</a></li>
                        </ul>

                            <li> Deep Generative Models
                            <ul style="padding-left:0;margin-left: 1.2em;font-size: 14px;">
                            <li>GANs and VAEs, Deep Learning Indaba 2019, <a href="https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2019/blob/master/3b_generative_models.ipynb">link</a> </li>
                <li>Denoising Diffusion, Deep Learning Indaba 2012, <a href="https://github.com/deep-learning-indaba/indaba-pracs-2022/blob/main/practicals/deep_generative_models.ipynb
                            ">link</a> </li>
                             </ul>

                     </ul>

                     <p style="font-size: 18px;">Project.</a>
                     </p>
                        The course project will give the students a chance to explore MCMC and/or generative modeling in greater detail. Course projects will be done in groups of up to 3 students and can fall into one or more of the following categories:
                        <ul style="padding-left:0;margin-left: 1.2em;font-size: 14px;">
<li>Application of MCMC or deep generative models on a novel task/dataset.</li>
<li>Algorithmic improvements into the evaluation, learning and/or inference of deep generative models.</li>
<li>Theoretical analysis of any aspect of existing deep generative models.</li>
 </ul>
The report must include theoretical, methodological and experimental considerations. You will be evaluated on these three aspects. Please indicate the contribution of each member of the team in the report. We do not expect the students to reproduce some of the high-dimensional experiments presented in some of these papers as we are aware of the compute limitations.<br><br>
The deadline for submission is 26th of April. You will be asked to present your result during an oral defence (eg with slides and/or notebook).
Please send your<br>
* pdf<br>
* colab link with experiments/code<br>
to anna.korba@ensae.fr.
                        </p>
                        Some examples:
                         <ul style="padding-left:0;margin-left: 1.2em;font-size: 14px;">
                            
                            <li> Implement in Python Langevin Monte Carlo with birth and death dynamics as in <a href="https://arxiv.org/pdf/1905.09863.pdf">this paper</a> or <a href="https://arxiv.org/pdf/2305.05529.pdf">that paper</a>. No need to fully undertand the paper, but at least the pseudocode and reproduce the experiments. Can you identify setting where birth-death dynamics improve over standard LMC?<br>  
                         </li>
                         <li> Study the results of Bayesian logistic regression on real data (see <a href="https://github.com/WillKoehrsen/Data-Analysis/blob/master/bayesian_log_reg/Bayesian-Logistic-Regression.ipynb">here</a> for an example of what can be done) on a classification dataset (see UCI repository, or some examples as the ones in Section 5 of  <a href="https://arxiv.org/pdf/1608.04471.pdf">this paper</a>).<br>  
                         </li>
                         <li> Investigate the performance of Bayesian Neural Networks (see a pytorch implementation <a href="https://github.com/JavierAntoran/Bayesian-Neural-Networks">here</a>) on different datasets (eg Fashion Mnist, or other classification datasets as the ones in Section 5 of  <a href="https://arxiv.org/pdf/1608.04471.pdf">this paper</a>).<br>  
                         </li>
                            <li> Investigate the data mollification effect as in <a href="https://arxiv.org/pdf/2305.18900.pdf">this paper</a> to compare different generative models on a set of experiments.<br>  
                         </li>

                     </ul>


                    </div>
                </div>
            </div>
        </div>
        <!-- /#page-content-wrapper -->

    </div>
    <!-- /#wrapper -->

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Menu Toggle Script -->
    <script>
    $("#menu-toggle").click(function(e) {
        e.preventDefault();
        $("#wrapper").toggleClass("toggled");
    });
    </script>

</body>

</html>
